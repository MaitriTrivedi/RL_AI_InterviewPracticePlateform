{
  "version": "model_v1_20250510_103432_reward_0.637",
  "metrics": {
    "actor_loss": NaN,
    "value_loss": 26.368636108402725,
    "entropy_loss": NaN,
    "total_loss": 0.0,
    "mean_reward": 0.6369542992878359,
    "clip_fraction": 0.0,
    "approx_kl": 0.3878866213734116,
    "difficulty_accuracy": 0.0,
    "topic_diversity": 0.0,
    "learning_rate": 0.0009900332916666667,
    "policy_std": 0.13613403858488746
  },
  "timestamp": "20250510_103432"
}